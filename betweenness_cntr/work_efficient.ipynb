{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work_efficient.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-_kIr7R1II3"
      },
      "source": [
        "Author: **Jaydeep Godbole** \\\\\n",
        "Roll Number: **17IE10039**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPeKUFIhJuIa",
        "outputId": "751c2292-77e4-49f6-c44c-cd3999db98e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytkkJIpaLhzs",
        "outputId": "4e3eff4c-5c0a-45fb-a314-29a08fb60782"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-kg6txps4\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-kg6txps4\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=994ac4a1a928813d2c7f0c066f8319477cd3795c8f8798fedeac54c0cab0e17b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tka8zdsf/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-OhPg7RL2v6",
        "outputId": "1376ec71-ff09-47ad-a7b3-8748c3c55eed"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vuKF7pAitzw1",
        "outputId": "7a99321e-a1d3-435a-89ca-9d62cbcdac80"
      },
      "source": [
        "%%cuda --name utils.h\n",
        "#ifndef UTILS\n",
        "#define UTILS\n",
        "\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "namespace utils{\n",
        "class graph\n",
        "{\n",
        " public:\n",
        " int n;\n",
        " int m;\n",
        " int * edges_from;\n",
        " int * edges_to;\n",
        " int * edges;\n",
        " int * scores;\n",
        "\n",
        " void print_edges()\n",
        " {\n",
        "  for(int i = 0; i < n; i++)\n",
        "  {\n",
        "   std::cout << \"Starting \" << i;\n",
        "   /*for(int j = edges_from[i]; j <= edges_to[i]; j++)\n",
        "   {\n",
        "    std::cout << edges[j] << std::endl;\n",
        "   }*/\n",
        "   if (edges_to[i] == -1)\n",
        "   {\n",
        "    std::cout << 0 << std::endl;\n",
        "   }\n",
        "   else\n",
        "   {\n",
        "    std::cout << (edges_to[i]-edges_from[i] + 1) << std::endl;\n",
        "   }    \n",
        "    \n",
        "  }\n",
        " }\n",
        " void print_scores_to_file(char * file);\n",
        "};\n",
        "\n",
        "graph initialize(std::vector<std::vector<int>> connections)\n",
        "{\n",
        " utils::graph g;\n",
        " g.m = connections.size(); // Number of edges\n",
        " g.n = 0;\n",
        " for(int i = 0; i < g.m; i++)\n",
        " {\n",
        "  if(connections[i][0]>g.n) g.n = connections[i][0];\n",
        "  if(connections[i][1]>g.n) g.n = connections[i][1];\n",
        "  \n",
        " }\n",
        " g.n += 1; // Number of nodes = max_idx + 1\n",
        "\n",
        " g.edges_from = new int[g.n]; //edges_from[i] is the index which neighbors of node i start. go up till edges_to[i]\n",
        " g.edges_to = new int[g.n]; \n",
        " g.edges = new int[2*g.m];\n",
        " g.scores = new int[g.n];\n",
        "\n",
        " for(int i = 0; i < g.n; i++)\n",
        " {\n",
        "  g.edges_from[i] = -1;\n",
        "  g.edges_to[i] = -1;\n",
        " }\n",
        "\n",
        " int curr_edge_pointer = 0;\n",
        "\n",
        " /* Changing here               ------------\n",
        " for(int i = 0; i < g.n; i++)\n",
        " {\n",
        "  bool isassigned = 0;\n",
        "  for(int j = 0; j < g.m; j++)\n",
        "  {\n",
        "   if(connections[j][0]==i)\n",
        "   {\n",
        "    if(!isassigned)\n",
        "    {\n",
        "     g.edges_from[i] = curr_edge_pointer;\n",
        "     isassigned = 1;\n",
        "    }\n",
        "    g.edges[curr_edge_pointer] = connections[j][1];\n",
        "    curr_edge_pointer += 1; \n",
        "   }\n",
        "   else if(connections[j][1]==i)\n",
        "   {\n",
        "    if(!isassigned)\n",
        "    {\n",
        "     g.edges_from[i] = curr_edge_pointer;\n",
        "     isassigned = 1;\n",
        "    }\n",
        "    g.edges[curr_edge_pointer] = connections[j][0];\n",
        "    curr_edge_pointer += 1; \n",
        "   }\n",
        "   if(isassigned)\n",
        "   {\n",
        "   g.edges_to[i] = curr_edge_pointer - 1;\n",
        "   }\n",
        "  }\n",
        " }Till here  -----------------------\n",
        "*/ \n",
        " //  New -------------------\n",
        " for(int i = 0; i < g.n; i++)\n",
        " {\n",
        "  for(int j = 0; j < g.m; j++)\n",
        "  {\n",
        "   if(connections[j][0]==i || connections[j][1]==i)\n",
        "   {\n",
        "    if (g.edges_from[i] == -1)\n",
        "    {\n",
        "     g.edges_from[i] = curr_edge_pointer;\n",
        "    }\n",
        "    if(connections[j][0]==i)    g.edges[curr_edge_pointer] = connections[j][1];\n",
        "    else g.edges[curr_edge_pointer] = connections[j][0];\n",
        "    curr_edge_pointer += 1;\n",
        "   }\n",
        "  }\n",
        "  if(g.edges_from[i] != -1)\n",
        "  {\n",
        "   g.edges_to[i] = curr_edge_pointer-1;\n",
        "  }\n",
        " }\n",
        " // New over ----------------------\n",
        "\n",
        " std::cout << g.n << \" \" << g.m << std::endl;\n",
        " std::cout << curr_edge_pointer/2 << std::endl;\n",
        "\n",
        " return g;\n",
        "}\n",
        "\n",
        "}\n",
        "#endif"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/utils.h'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hids3Kv-qIrk",
        "outputId": "2d36261f-3e99-4a99-c087-da82aa13173d"
      },
      "source": [
        "%%cuda --name work_efficient_kernels.h\n",
        "#ifndef KERNELS\n",
        "#define KERNELS\n",
        "\n",
        "#include </content/src/utils.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "\n",
        "__global__ void get_bc(const int * edges_from, const int * edges_to, const int * edges, const int m, const int n, float * bc, int * Q1, int * Q2, int * Q1_len, int * Q2_len, int * dist, int * num_shortest_paths, int * S, int * S_ends, int * S_len, float * bc_local)\n",
        "{\n",
        " int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        " // Initialize all global arrays and stuff to 0 \n",
        "\n",
        " for(int k = 0; k < (n + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        " {\n",
        "  if(k*gridDim.x*blockDim.x + i < n)\n",
        "  {\n",
        "   if(k==0 && i==0)\n",
        "   {\n",
        "    Q1_len[0] = 0;\n",
        "    Q2_len[0] = 0;  // Empty queues\n",
        "   }\n",
        "   bc[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   bc_local[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   Q1[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   Q2[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   dist[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   num_shortest_paths[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   S[i + k*gridDim.x*blockDim.x] = 0;\n",
        "   S_ends[i + k*gridDim.x*blockDim.x] = 0;\n",
        "  }\n",
        " }\n",
        "\n",
        " __syncthreads();\n",
        " \n",
        "\n",
        " for(int source = 0; source < n; source++)\n",
        " {\n",
        "  __syncthreads();\n",
        "  // New node, so set dist, num_shortest paths and bc_local to be zero!\n",
        "  \n",
        "  for(int k = 0; k < (n + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        "  {\n",
        "    if(k*gridDim.x*blockDim.x + i < n)\n",
        "    {\n",
        "      if(k==0 && i==0)\n",
        "      {\n",
        "      S_len[0] = 0;\n",
        "      Q1_len[0] = 0;\n",
        "      Q2_len[0] = 0;\n",
        "      }\n",
        "      bc_local[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      Q1[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      Q2[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      dist[i + k*gridDim.x*blockDim.x] = INT_MAX;\n",
        "      num_shortest_paths[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      S[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      S_ends[i + k*gridDim.x*blockDim.x] = 0;\n",
        "      }\n",
        "  }\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  int max_penultimate_depth = 0;\n",
        "\n",
        "  // Run the shortest path calculation, from the source node outwards\n",
        "  \n",
        "  if(i==0)\n",
        "  {\n",
        "   // Only setting the source node here\n",
        "   Q1[0] = source;\n",
        "   Q1_len[0] = 1;\n",
        "   dist[source] = 0;\n",
        "   num_shortest_paths[source] = 1;\n",
        "   S[0] = source;\n",
        "   S_ends[0] = 0;\n",
        "   S_len[0] = 1;\n",
        "  }\n",
        "  // Now, Q1 has the source node, Q2 is empty, S, S_ends have been assigned\n",
        "\n",
        "  int curr_depth = 0; // Depth is defined as the distance of the frontier from the source\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  while(1)\n",
        "  {\n",
        "   // There are still unexplored nodes. Everything till current depth is done\n",
        "   // Find next frontier nodes in parallel\n",
        "\n",
        "   for(int k = 0; k < (Q1_len[0] + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        "   {\n",
        "    if(k*gridDim.x*blockDim.x + i < Q1_len[0])\n",
        "    {\n",
        "     for(int neighbors_idx = edges_from[Q1[k*gridDim.x*blockDim.x + i]]; neighbors_idx <= edges_to[Q1[k*gridDim.x*blockDim.x + i]]; neighbors_idx++)\n",
        "     {\n",
        "      // neighbors_idx is a neighbor of a node in the current frontier\n",
        "      if(atomicCAS(&dist[edges[neighbors_idx]], INT_MAX, curr_depth + 1) == INT_MAX)\n",
        "      {\n",
        "       // It is an unexplored node\n",
        "       int temp = atomicAdd(&Q2_len[0], 1);\n",
        "       Q2[temp] = edges[neighbors_idx];\n",
        "      }\n",
        "      if(dist[edges[neighbors_idx]] == curr_depth + 1)\n",
        "      {\n",
        "       atomicAdd(&num_shortest_paths[edges[neighbors_idx]], num_shortest_paths[Q1[k*gridDim.x*blockDim.x + i]]);\n",
        "      }\n",
        "     }\n",
        "    }\n",
        "   }\n",
        "   \n",
        "   __syncthreads();\n",
        "\n",
        "   int next_frontier_len = Q2_len[0];\n",
        "\n",
        "   if(next_frontier_len == 0)\n",
        "   {\n",
        "    max_penultimate_depth = curr_depth - 1;\n",
        "    break;\n",
        "   }\n",
        "   else\n",
        "   {\n",
        "    for(int k = 0; k < (next_frontier_len + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        "    {\n",
        "     if(k*gridDim.x*blockDim.x + i < next_frontier_len)\n",
        "     {\n",
        "      // Move Q2 into Q1\n",
        "      Q1[k*gridDim.x*blockDim.x + i] = Q2[k*gridDim.x*blockDim.x + i];\n",
        "      S[k*gridDim.x*blockDim.x + i + S_len[0]] = Q2[k*gridDim.x*blockDim.x + i];\n",
        "     }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    curr_depth = curr_depth + 1;\n",
        "    S_ends[curr_depth] = S_ends[curr_depth - 1] + next_frontier_len;\n",
        "    Q1_len[0] = next_frontier_len;\n",
        "    S_len[0] = S_len[0] + next_frontier_len;\n",
        "    Q2_len[0] = 0;\n",
        "    __syncthreads();\n",
        "   }\n",
        "   __syncthreads();\n",
        "\n",
        "  }\n",
        "  \n",
        "  while(max_penultimate_depth > 0)\n",
        "  {\n",
        "   for(int k = 0; k < (S_ends[max_penultimate_depth] - S_ends[max_penultimate_depth - 1] + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        "   {\n",
        "    if(k*gridDim.x*blockDim.x + i < S_ends[max_penultimate_depth] - S_ends[max_penultimate_depth - 1])\n",
        "    {\n",
        "     int curr_frontier_node = S[S_ends[max_penultimate_depth - 1] + 1 + k*gridDim.x*blockDim.x + i];\n",
        "     float curr_frontier_node_dependency = 0;\n",
        "     int curr_frontier_node_paths = num_shortest_paths[curr_frontier_node];\n",
        "     \n",
        "     for(int neighbors_idx = edges_from[curr_frontier_node]; neighbors_idx <= edges_to[curr_frontier_node]; neighbors_idx++)\n",
        "     {\n",
        "      if(dist[edges[neighbors_idx]] == max_penultimate_depth + 1)\n",
        "      {\n",
        "       curr_frontier_node_dependency = curr_frontier_node_dependency + ((float)curr_frontier_node_paths)/(num_shortest_paths[edges[neighbors_idx]]) * (1.0 + bc_local[edges[neighbors_idx]]);\n",
        "      }\n",
        "     }\n",
        "     bc_local[curr_frontier_node] = curr_frontier_node_dependency;\n",
        "    }\n",
        "   }\n",
        "\n",
        "   __syncthreads();\n",
        "   max_penultimate_depth = max_penultimate_depth - 1;\n",
        "  }\n",
        "\n",
        "  __syncthreads();\n",
        "\n",
        "  // Dependency d_s(v) has been stored in bc_local, and so this will be parallelly accumulated in bc\n",
        "\n",
        "  for(int k = 0; k < (n + gridDim.x*blockDim.x - 1)/(gridDim.x*blockDim.x); k++)\n",
        "  {\n",
        "   if(k*gridDim.x*blockDim.x + i < n)\n",
        "   {\n",
        "    bc[k*gridDim.x*blockDim.x + i] = bc[k*gridDim.x*blockDim.x + i] + bc_local[k*gridDim.x*blockDim.x + i];\n",
        "   }\n",
        "  }\n",
        "  __syncthreads();\n",
        " }\n",
        "\n",
        "}\n",
        "\n",
        "float * work_efficient_bc_gpu(utils::graph g)\n",
        "{\n",
        " cudaDeviceProp prop;\n",
        " cudaError_t err = cudaSuccess;\n",
        " err = cudaGetDeviceProperties(&prop, 0);\n",
        " if(err != cudaSuccess)\n",
        " {\n",
        "  std::cout << \"Failed\" << std::endl;\n",
        "  exit(EXIT_FAILURE);\n",
        " }\n",
        " std::cout << \"Chosen Device: \" << prop.name << std::endl;\n",
        " std::cout << \"Compute Capability: \" << prop.major << \".\" << prop.minor << std::endl;\n",
        " std::cout << \"Number of Streaming Multiprocessors: \" << prop.multiProcessorCount << std::endl;\n",
        " std::cout << \"Size of Global Memory: \" << prop.totalGlobalMem/(float)(1024*1024*1024) << \" GB\"<< std::endl;\n",
        "\n",
        " int max_threads_per_block = prop.maxThreadsPerBlock;\n",
        " int num_SMs = prop.multiProcessorCount;\n",
        " \n",
        " int * d_edges = NULL;\n",
        " int * d_edges_from = NULL;\n",
        " int * d_edges_to = NULL;\n",
        " float * d_bc = NULL;\n",
        " float * d_bc_local = NULL;\n",
        " int * Q1 = NULL;\n",
        " int * Q2 = NULL;\n",
        " int * Q1_len = NULL;\n",
        " int * Q2_len = NULL;\n",
        " int * S_len = NULL;\n",
        " int * dist = NULL;\n",
        " int * num_shortest_paths = NULL;\n",
        " int * S = NULL;\n",
        " int * S_ends = NULL;\n",
        "\n",
        "\n",
        " size_t size = g.n*sizeof(int);\n",
        " err = cudaMalloc((void**)&d_edges_from, size);\n",
        " if(err!=cudaSuccess){std::cout<<\"1\"<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMemcpy(d_edges_from, g.edges_from, size, cudaMemcpyHostToDevice);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&d_edges_to, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMemcpy(d_edges_to, g.edges_to, size, cudaMemcpyHostToDevice);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&Q1, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&Q2, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&dist, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&num_shortest_paths, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&S, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&S_ends, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " \n",
        " size = sizeof(int);\n",
        " err = cudaMalloc((void**)&Q1_len, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&Q2_len, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&S_len, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " \n",
        " size = g.n*sizeof(float);\n",
        " err = cudaMalloc((void**)&d_bc, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMalloc((void**)&d_bc_local, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " \n",
        " size = 2*g.m*sizeof(int);\n",
        " err = cudaMalloc((void**)&d_edges, size);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " err = cudaMemcpy(d_edges, g.edges, size, cudaMemcpyHostToDevice);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        " \n",
        " cudaEvent_t start, stop;\n",
        " cudaEventCreate(&start);\n",
        " cudaEventCreate(&stop);\n",
        "\n",
        " cudaEventRecord(start);\n",
        " get_bc<<<num_SMs, max_threads_per_block>>>(d_edges_from, d_edges_to, d_edges, g.m, g.n, d_bc, Q1, Q2, Q1_len, Q2_len, dist, num_shortest_paths, S, S_ends, S_len, d_bc_local);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float milliseconds = 0;\n",
        " cudaEventElapsedTime(&milliseconds, start, stop);\n",
        " \n",
        " std::cout << \"The running time is \" << milliseconds << \"milliseconds\" << std::endl;\n",
        " \n",
        " float * bc_calculated = new float[g.n];\n",
        "\n",
        " for(int i = 0; i < g.n; i++)\n",
        " {\n",
        "  bc_calculated[i] = 1.0;\n",
        " }\n",
        "\n",
        " size = g.n*sizeof(float);\n",
        " err = cudaMemcpy(bc_calculated, d_bc, size, cudaMemcpyDeviceToHost);\n",
        " if(err!=cudaSuccess){std::cout<<cudaGetErrorString(err)<<std::endl; exit(EXIT_FAILURE);}\n",
        "\n",
        " return bc_calculated;\n",
        "\n",
        "}\n",
        "\n",
        "#endif"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/work_efficient_kernels.h'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyhRlxfEL9T6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39e2c19e-0c0d-4f0c-9315-1722f5d36518"
      },
      "source": [
        "%%cuda --name work_efficient_main.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <sstream>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <boost/algorithm/string.hpp>\n",
        "#include </content/src/utils.h>\n",
        "#include </content/src/work_efficient_kernels.h>\n",
        "\n",
        "using namespace std;\n",
        "class graph\n",
        "{\n",
        " // Defining the graph data structure for handling large graphs\n",
        " public:\n",
        " int n; // Number of nodes in the graph\n",
        " int m; // Number of edges in the graph\n",
        " //std::vector<int*> begin;\n",
        " //std::vector<int*> end;\n",
        " int * begin;\n",
        " int * end;\n",
        " int * edges;\n",
        "\n",
        "\n",
        "};\n",
        "int main(int argc, char** argv)\n",
        "{\n",
        " // First argument is the graph name (relative to the main directory).\n",
        "\n",
        " std::string s = argv[1];\n",
        "\n",
        " if(s.find(\".txt\") != std::string::npos)\n",
        "  {\n",
        "\t\t;//return 0;//generate_graph(file);\n",
        "\t}\n",
        "\telse if(s.find(\".edge\") != std::string::npos)\n",
        "\t{\n",
        "\t\t;//return 0;//generate_graph(file);\n",
        "\t}\n",
        "\telse\n",
        "\t{\n",
        "\t\tstd::cerr << \"Error: Unsupported file type.\" << std::endl;\n",
        "\t\texit(-1);\n",
        "\t}\n",
        " std::string datapath = \"drive/MyDrive/HP3/Betweenness_Centrality/dataset/\"; \n",
        " s = datapath + s;\n",
        " std::cout << s << std::endl;\n",
        " std::fstream fin(s);\n",
        " std::string line;\n",
        " std::fstream graph_file;\n",
        " graph_file.open(s, ios::in);\n",
        " if(!graph_file)\n",
        " {\n",
        "  cout << \"File doesn't exist\" << endl;\n",
        " }\n",
        " else\n",
        " {\n",
        "  cout << \"Graph file exists\" << endl;\n",
        " }\n",
        " vector<vector<int>> edges;\n",
        " vector<int> temp;\n",
        " while (getline(fin, line)) {\n",
        "  temp.clear();\n",
        "  // Split line into tab-separated parts\n",
        "  std::vector<std::string> parts;\n",
        "  boost::algorithm::split(parts, line, boost::is_any_of(\" \"));\n",
        "  // TODO Your code goes here!\n",
        "  for(int i = 0; i < parts.size(); i++)\n",
        "  {\n",
        "   stringstream s(parts[i]);\n",
        "   int k;\n",
        "   s >> k;\n",
        "   temp.push_back(k);\n",
        "  }\n",
        "  if(temp.size()!=2){\n",
        "      cout << temp.size();\n",
        "      cerr << \"Format incorrect\" << endl;\n",
        "      return -1;\n",
        "  }\n",
        " edges.push_back(temp);\n",
        " }\n",
        " fin.close();\n",
        " cout << \"Number of edges in the graph: \" << edges.size() << endl;\n",
        "\n",
        " utils::graph g = utils::initialize(edges);\n",
        "\n",
        " float * bc = work_efficient_bc_gpu(g);\n",
        "\n",
        " /*for(int i = 0; i < g.n; i++)\n",
        " {\n",
        "  g.scores[i] = bc[i];\n",
        "  std::cout << bc[i] << std::endl;\n",
        " }*/\n",
        " \n",
        " return 0;\n",
        "\n",
        " \n",
        "}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/work_efficient_main.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iP76nnGENm9"
      },
      "source": [
        "!nvcc /content/src/work_efficient_main.cu -o /content/src/work_efficient_main"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXzYoxr5Ft7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766932c8-236c-45aa-cf64-e7f4fa11f29e"
      },
      "source": [
        "!/content/src/work_efficient_main CA-GrQc-new.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/HP3/Betweenness_Centrality/dataset/CA-GrQc-new.txt\n",
            "Graph file exists\n",
            "Number of edges in the graph: 28980\n",
            "5242 28980\n",
            "28974\n",
            "Chosen Device: Tesla T4\n",
            "Compute Capability: 7.5\n",
            "Number of Streaming Multiprocessors: 40\n",
            "Size of Global Memory: 14.7556 GB\n",
            "The running time is 1431.65milliseconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-N9Ax1eP2K0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}